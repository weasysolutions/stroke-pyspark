{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tercera Lección "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### _<font color=blue>  Objetivo de la lección: </font>_\n",
    "\n",
    "<font color=blue>\n",
    " Aprender las diferentes fases del Aprendizaje de Datos (ML): Ingeniería de caacterísticas y Modelado de Datos.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align=\"center\">El flujo de trabajo en un proyecto de ciencia de datos </h2>\n",
    "\n",
    "El conjunto de  lineamientos específicos ('ducto') en un proyecto de  ciencia de datos varía dependiendo de la naturaleza del mismo. Aquí trabajamos el ducto estandar:\n",
    "\n",
    "### Análisis exploratorio de los datos\n",
    "\n",
    "### Ingeniería de Características\n",
    "\n",
    "### Modelado de datos\n",
    "\n",
    " ***\n",
    " Especificamente en esta leccion nos enfocamos en los dos últimos puntos\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "_Ajustamos un poco el estilo de este libro trabajo para tener graficas centradas_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Análisis exploratorio de los datos\n",
    "Los resultados de la lección pasada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Características\n",
    "Los nombres de las características del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "caracteristicas =  ['a:radio','b:textura','c:perimetro', \\\n",
    "             'd:area', 'e:suavidad','f:compactes', \\\n",
    "             'g:concavidad', 'h:puntos_concavos','i:simetria',\\\n",
    "             'j:dimension_fractal']\n",
    "\n",
    "columnas = ['ID', 'Diagnostico'] + \\\n",
    "              list(map(lambda x: x[2:] + '_promedio', caracteristicas)) + \\\n",
    "              list(map(lambda x: x[2:] + '_error', caracteristicas)) +  \\\n",
    "              list(map(lambda x: x[2:] + '_peor', caracteristicas))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "####  Extracción \n",
    "Importamos la librería **Pandas** para extraer el conjunto de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../data/wisconsin.csv', names = columnas);\n",
    "data = data.reset_index().drop(columns =['index'])\n",
    "data = data.drop(columns='ID')\n",
    "\n",
    "data['Benigno'] = (data['Diagnostico']=='B')*1\n",
    "data['Maligno'] = 1 - data['Benigno']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La ingeniería de características es el proceso de utilizar el conocimiento de dominio de los datos para crear características que hacen que los algoritmos de aprendizaje automático funcionen. La ingeniería de características es fundamental para la aplicación del aprendizaje automático.\n",
    "\n",
    "## Ingeniería de Características\n",
    "\n",
    " - Datos Categóricos\n",
    " - Divsion del conjunto de datos\n",
    " - Escalamiento de los atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ingeniería de Características\n",
    "\n",
    "### Datos Categóricos\n",
    "\n",
    "Los datos categóricos son variables que contienen valores de etiqueta en lugar de valores numéricos. El número de valores posibles a menudo se limita a un conjunto fijo.\n",
    "\n",
    "Por ejemplo, los usuarios normalmente se describen por país, género, grupo de edad, etc.\n",
    "\n",
    "De hecho ya hemos  convertido los atributos del _Diagnóstico_ a valores numéricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maligno</th>\n",
       "      <th>Benigno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Maligno  Benigno\n",
       "32         1        0\n",
       "229        1        0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Maligno','Benigno']].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las columnas _Maligno_ y _Benigno_ son redundates. El conocimiento de una, automaticamente nos define la otra. Eliminamos una:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns = 'Maligno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En este punto la columna _Diagnostico_ tambien se vuelve redundante, por lo que también la eliminamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns = 'Diagnostico')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### División del conjunto de datos \n",
    "\n",
    "Los datos que utilizamos generalmente se dividen en datos de _entrenamiento_ y datos de _prueba_. \n",
    "El conjunto de entrenamiento contiene _un_ resultado conocido y \n",
    "el modelo aprende sobre estos datos para generalizarse a otros datos más adelante. \n",
    "Tenemos el conjunto de datos de prueba (o subconjunto) para probar la predicción de nuestro modelo \n",
    "en este subconjunto.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "***\n",
    "Primero, separamos el conjunto total de diagnósticos (presentado por la letra _Y_) del resto de los atributos (representados por la letra _X_)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:, 0:29].values\n",
    "Y = data.iloc[:, 30].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Separamos el conjunto de entrenamiento y el conjunto prueba usando la biblioteca **SciKit-Learn**. Más en especifico, usamos el método 'train_test_split':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El parametro test_\\__size_ que aparece en el método\n",
    "\n",
    "_train_\\__test_\\__split()_\n",
    "\n",
    "representa el porcentaje de los datos _(X,Y)_  que serán usados como datos de prueba. En nuestro caso hemos usado el veinticinco porciento. El parámetro _random_\\__state_ sirve para establecer la semilla del algoritmo aleatorio que selecciona los conjuntos de datos \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Escalamiento de los atributos \n",
    "\n",
    "La mayoría de las veces, un conjunto de datos contendrá características altamente variables en su magnitudes, unidades y rango. Por ejemplo notemos la gran disparidad que existe entre las columnas 'dimension_fractal' y 'radio_promedio':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_promedio</th>\n",
       "      <th>dimension_fractal_promedio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.062798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.007060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.049960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.057700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.061540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.066120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.097440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       area_promedio  dimension_fractal_promedio\n",
       "count     569.000000                  569.000000\n",
       "mean      654.889104                    0.062798\n",
       "std       351.914129                    0.007060\n",
       "min       143.500000                    0.049960\n",
       "25%       420.300000                    0.057700\n",
       "50%       551.100000                    0.061540\n",
       "75%       782.700000                    0.066120\n",
       "max      2501.000000                    0.097440"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['area_promedio','dimension_fractal_promedio']].describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " Asi como la cercania o lejania entre dos ciudades distintas se establece con la distancia que los separa, en estadística también tenemos el concepto de distancia entre los datos _medidos_ con los datos del _modelo teórico_. De hecho, la noción de distancia en estadística es la misma que la que hay para dos ciudades: la medida Euclideana.\n",
    " Con ella, podemos decir si nuestras predicciones del modelo están cerca o lejos de las predicciones de los datos medidos. Es un poco descabellado comparar distancias de ciudades con las distancias entre dos hormigas en un mismo hormiguero, pero los ejemplos del 'area_promedio' y 'dimension_fractal_promedio' arriba expuestos  nos  están demostrando que semejantemente nos encontramos en esta situacion.\n",
    " ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "_<div style=\"text-align: center\">  Es deseable llevar todas las características al mismo nivel de magnitudes (normalizar los datos). Esto se puede lograr mediante la escala. Esto significa transformar todos los datos a una misma  escala específica, \n",
    "como  de 0 a 100 o de  0 a 1.  </div>_\n",
    " ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para normalizar los datos, usamos el metodo _StandardScaler_ de la bilbioteca **sklearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Modelado de datos\n",
    "\n",
    "El modelado de datos en ingeniería de software representa el proceso de crear un modelo de datos para un sistema de información mediante la aplicación de las técnicas de Aprendizaje de Datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En el área del aprendizaje de maquinas, las predicciones se diferencían  en dos tipos. Por un lado, las predicciones que toman valores en el  continúo (en la recta real), se les llama _Regresiones_. Por ejemplo, el tiempo que tarda un avion en cruzar el continente. Mientras que las predicciones que involucran solo un número finito de predicciones (discreto o categórico), se les conoce como _clasificaciones_. Por ejemplo un conjunto de tres colores, el día o la noche, etc.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En nuestro caso queremos predicir si el cancer es maligno o benigno, entonces usaremos _algoritmos de clasificación para el aprendizaje supervisado_ \n",
    "***\n",
    "La palabra supervisado, aquí significa que sabemos que etiqueta final queremos predecir: _Benigno_ o _Maligno_. Las etiquetas _Benigno_  y _Maligno_ que usamos para entrenar a la maquina, no deben ser llamadas  _predicciones_ sino _datos de salida_: toda prediccion es un dato de salida pero no al reves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clasificación in ML\n",
    "EN SUMA:\n",
    "\n",
    "En aprendizaje automático y estadística, la clasificación consiste identificar a cuál de un conjunto de categorías (subpoblaciones) pertenece una nueva observación, sobre la base de un conjunto de entrenamiento de datos que contienen observaciones (o instancias) cuya categoría de miembro es conocida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algoritmos de ML\n",
    "\n",
    "Los siguientes nombres de algoritmos de clasificación en Aprendizaje Automático, son de los más populares en el mundo de la ciencia de datos:\n",
    "\n",
    "1. Regresión Logística\n",
    "\n",
    "2. Vecino Más Cercano\n",
    "\n",
    "3. Soporte de Máquinas de Vectores\n",
    "\n",
    "4. Kernel SVM\n",
    "\n",
    "5. Naïve Bayes\n",
    "\n",
    "6. Árbol de Decisión\n",
    "\n",
    "7. Bosques al Azar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La biblioteca **sklearn** incluye todos estos métodos. A continuación describimos cada uno de los métodos e importamos las correspondientes sub-librerias .\n",
    "\n",
    "Ejemplificamos a detalle el análisis que hacemos de los datos para el caso de  la  _regresión logística_. Despues introducimos los demás algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### REGRESIÓN LOGÍSTICA.\n",
    "\n",
    "En su forma más sencilla (la cual es la que necesitamos aqui), la regresión logística modela las variables de salida 'Benigno y 'Maligno', en este caso hablamos de una _regresión logística binaria_\n",
    "\n",
    "\n",
    "El resultado de un paciente no influyen en los demás, entonces las pruebas de los pacientes constituyen un\n",
    "__Ensayo de Bernoulli:__\n",
    "Ensayos repetidos independientes de un experimento con exactamente dos resultados posibles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Regresión Logística vs Regresión Ordinaria\n",
    "La regresión logística difiere de la regresión ordinaria en que la segunda regresa valores continuos. En la regresión logísitica, la simplicidad de la regresión lineal es usada, pero tiene que ser adicionada con  una forma de convertir una variable binaria en una continua que pueda tomar cualquier valor real (negativo o positivo). \n",
    "\n",
    "Para ello se definen  la _frontera de decisión_ (_boundary decision_). \n",
    "\n",
    "Esta predicción categórica se puede basar en las probabilidades calculadas de éxito, y las probabilidades pronosticadas por encima de un valor de corte elegido se traducen en una predicción de éxito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Funciones de Activación\n",
    "\n",
    "Computacionalmente a veces es mejor aproximar probabilidades de valores categóricos con funciones continuas conocidas como funciones de activación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ejemplo\n",
    "Las siguientes dos funciones, son funciones de activacion y se conocen como las funciones _sigmoid_ y _tanh_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff5af0cbdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):  \n",
    "    return  np.array([1 / (1 + np.exp(-y)) for y in x])\n",
    "\n",
    "def tanh(x):\n",
    "    return np.array([np.tanh(y) for y in x])\n",
    "\n",
    "t = np.linspace(-4,4,400)\n",
    "\n",
    "a = 4*sigmoid(t) - 2\n",
    "b = 1*tanh(t) + 0\n",
    "\n",
    "plt.plot(t,a,t,b)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A continuación cargamos el método de regresión logística de **skit-learn** que hará el _ajuste_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Logistic Regression Algorithm to the Training Set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "\n",
    "#Una vez cargado el clasificador, hacemos el ajuste\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Teniendo el _clasificador_ entrenado, toca el turno de generar predicciones (_respuestas_) para el conjunto de prueba (_predictór_ ) X_test,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para verificar la precisión de la predicción importamos el método de confusión de matriz de métricas. La matríz de confusión es una forma de tabular el número de clasificaciones erróneas, es decir, el número de clases predichas (Y_pred) que terminaron en un contenedor de clasificación incorrecto basado en las clases verdaderas (Y_train)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Matríz de Error o Matríz de Confusión \n",
    "\n",
    "En el análisis predictivo, una tabla de confusión (o matríz de confusión), es una tabla con dos filas y dos columnas que informa el número de _falsos positivos_, _falsos negativos_, _verdaderos positivos_ y _verdaderos negativos_.\n",
    "\n",
    "Cada fila de la matríz representa las instancias en una clase predicha, mientras que cada columna representa las instancias en una clase real (o viceversa). En nuesro caso, tenemos algo como:\n",
    "\n",
    "\n",
    "| Prediccion/Real | Maligno | Benigno |\n",
    "| --- | --- | --- |\n",
    "| Maligno | $VP$ | $FP$|\n",
    "| Benigno | $FN$ | $VN$ |\n",
    "\n",
    "$VP$ = Número de  Verdadero Positivo\n",
    "\n",
    "$FP$ = Número de Falso Positivo\n",
    "\n",
    "$VN$ = Número de Verdadero Negativo\n",
    "\n",
    "$FN$ = Número de Falso Negativo\n",
    "\n",
    "\n",
    "**condición positiva (P):**\n",
    "El número de casos positivos reales en los datos.\n",
    "\n",
    "**condición negativa (N):**\n",
    "El número de casos negativos reales en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Importamos el método de métrica que contiene la matriz de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los 143 casos probados nos arrojan la siguiente matriz de confusión: \n",
      " [[49  4]\n",
      " [ 4 86]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#La matriz de confusión\n",
    "cm = metrics.confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "print('Los', len(Y_test), 'casos probados', \\\n",
    "      'nos arrojan la siguiente matriz de confusión: \\n', cm \n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exactitud \n",
    "\n",
    "Para el caso de errores categoricos (como en nuestro caso), esta simple clasificacion puede ser engañosa, por que las muestras pueden estar cargadas hacia un solo caso. Es recomendable apoyarnos en la _Exactitud Matematica_, la cual viene dada simplemente por la relacion:\n",
    "***\n",
    "$\\textit{Exactitud} = \\frac{\\text{Número de Predicciones Verdaderas}}{\\text{Número Total de Predicciones}}$\n",
    "\n",
    "\n",
    "Para nuestro caso de predicciones categóricas binarias:\n",
    "\n",
    "\n",
    "$\\textit{Exactitud} = \\frac{\\text{VP+VN}}{\\text{VP+VN+FP+FN}}$\n",
    "***\n",
    "El método _metrics.accuracy_score_ lo calcula por nosotros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440559440559441"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(Y_test, Y_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toca el turno de repetir el mismo ejercicio sobre las diferentes rutinas de Machine Learning que **sklearn** nos provee. Prim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clasificadores = {}\n",
    "\n",
    "#Para el conjunto de entrenamiento usamos:\n",
    "\n",
    "#Usando el Algoritmo de Regresion Logistica \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clasificadores['Regresion Logistica'] = LogisticRegression(random_state = 0)\n",
    "clasificadores['Regresion Logistica'].fit(X_train, Y_train)\n",
    "\n",
    "#Usando el Algoritmo de K Vecinos Próximos \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clasificadores['K Vecinos Próximos'] = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "clasificadores['K Vecinos Próximos'].fit(X_train, Y_train)\n",
    "\n",
    "#Usando el Algoritmo de Máquinas de Soporte Vectorial \n",
    "from sklearn.svm import SVC\n",
    "clasificadores['Máquinas de Soporte Vectorial'] = SVC(kernel = 'linear', random_state = 0)\n",
    "clasificadores['Máquinas de Soporte Vectorial'].fit(X_train, Y_train)\n",
    "\n",
    "#Usando el Algoritmo de Núcleo SVM \n",
    "from sklearn.svm import SVC\n",
    "clasificadores['Núcleo SVM '] = SVC(kernel = 'rbf', random_state = 0)\n",
    "clasificadores['Núcleo SVM '].fit(X_train, Y_train)\n",
    "\n",
    "#Usando el Algoritmo Bayessiano Ingenuo\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clasificadores['Bayes Ingenuo'] = GaussianNB()\n",
    "clasificadores['Bayes Ingenuo'].fit(X_train, Y_train)\n",
    "\n",
    "#Usando el Arbol de Decisión \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clasificadores['Arbol de Decisión'] = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "clasificadores['Arbol de Decisión'].fit(X_train, Y_train)\n",
    "\n",
    "#Usando el Bosque Aleatorio \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clasificadores['Bosque Aleatorio'] = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "clasificadores['Bosque Aleatorio'].fit(X_train, Y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "exactitudes = {}\n",
    "for clasificador in clasificadores:\n",
    "    \n",
    "    Y_pred = clasificadores[clasificador].predict(X_test) \n",
    "    \n",
    "    exactitudes[clasificador] = metrics.accuracy_score(Y_test, Y_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El clasificador Regresion Logistica es exacto hasta un 94.41 %\n",
      "El clasificador K Vecinos Próximos es exacto hasta un 95.80 %\n",
      "El clasificador Máquinas de Soporte Vectorial es exacto hasta un 96.50 %\n",
      "El clasificador Núcleo SVM  es exacto hasta un 96.50 %\n",
      "El clasificador Bayes Ingenuo es exacto hasta un 92.31 %\n",
      "El clasificador Arbol de Decisión es exacto hasta un 95.10 %\n",
      "El clasificador Bosque Aleatorio es exacto hasta un 95.80 %\n"
     ]
    }
   ],
   "source": [
    "for clasificador in exactitudes:\n",
    "    print('El clasificador', clasificador, 'es exacto hasta un',  '%.2f' % (100*exactitudes[clasificador]),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación cruzada\n",
    "\n",
    "Mucha veces en vez de dividir inicialmente el conjunto de datos en dos subconjuntos, lo hacemos en tres subconjuntos: _entrenamiento_, _validación_ y _prueba_\n",
    "\n",
    "dejan de lado el conjunto de pruebas y eligen aleatoriamente el X% \n",
    "de su conjunto de datos de tren para que sea el conjunto de trenes real y el restante (100-X)% \n",
    "para ser el conjunto de validación, donde X es un número fijo (por ejemplo, 80%). ), \n",
    "el modelo se entrena y valida iterativamente en estos diferentes conjuntos.\n",
    "Hay varias formas de hacer esto, y se conoce comúnmente como validación cruzada. \n",
    "Básicamente, utiliza su conjunto de entrenamiento para generar múltiples divisiones \n",
    "de los conjuntos de Entrenamiento y Validación. La validación cruzada evita el ajuste \n",
    "excesivo y se está volviendo cada vez más popular, siendo la Validación Cruzada K-fold \n",
    "el método más popular de validación cruzada.\n",
    "Mira esto para más.\n",
    "\n",
    "En el enfoque que estamos siguiendo (también muy común entre los practicantes del aprendizaje de datos) \n",
    "\n",
    "\n",
    "Nosotros estamos usando una forma especifica de _validacio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota sobre la validación cruzada: muchas veces,\n",
    "las personas primero dividen su conjunto de datos en 2 - Train and Test.\n",
    "Después de esto, dejan de lado el conjunto de pruebas y eligen aleatoriamente el X% \n",
    "de su conjunto de datos de tren para que sea el conjunto de trenes real y el restante (100-X)% \n",
    "para ser el conjunto de validación, donde X es un número fijo (por ejemplo, 80%). ), \n",
    "el modelo se entrena y valida iterativamente en estos diferentes conjuntos.\n",
    "Hay varias formas de hacer esto, y se conoce comúnmente como validación cruzada. \n",
    "Básicamente, utiliza su conjunto de entrenamiento para generar múltiples divisiones \n",
    "de los conjuntos de Entrenamiento y Validación. La validación cruzada evita el ajuste \n",
    "excesivo y se está volviendo cada vez más popular, siendo la Validación Cruzada K-fold \n",
    "el método más popular de validación cruzada.\n",
    "Mira esto para más."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas _Maligno_ y _Benigno_ son redundates. El conocimiento de una, automaticamente nos define la otra. Eliminamos una:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
